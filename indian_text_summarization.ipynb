{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "7L4K9-QJpTlI",
    "outputId": "b58b13cf-f041-4c39-f2a0-94b3e701de8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Collecting indic-nlp-library\n",
      "  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Collecting sphinx-argparse (from indic-nlp-library)\n",
      "  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting sphinx-rtd-theme (from indic-nlp-library)\n",
      "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting morfessor (from indic-nlp-library)\n",
      "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (2.2.2)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
      "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.5)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.12)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (8.2.3)\n",
      "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\n",
      "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n",
      "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
      "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.1)\n",
      "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.17.0)\n",
      "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\n",
      "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
      "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
      "Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n",
      "Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: morfessor, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, sphinxcontrib-jquery, sphinx-argparse, nvidia-cusolver-cu12, sphinx-rtd-theme, indic-nlp-library\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed indic-nlp-library-0.92 morfessor-2.0.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sphinx-argparse-0.5.2 sphinx-rtd-theme-3.0.2 sphinxcontrib-jquery-4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch indic-nlp-library sentencepiece gradio datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEbS-xB8r9wd",
    "outputId": "c5eea7b4-a0d0-40bb-e77b-8448be746b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08dUPnQGIs5L"
   },
   "source": [
    "# **Loading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "742p2SR5wNYZ",
    "outputId": "3a1cc91b-814a-45bf-b6f5-311c9ef509a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset (first 5 rows):\n",
      "                                            Headline  \\\n",
      "0  \u0915\u093e\u0902\u0917\u094d\u0930\u0947\u0938 \u0928\u0947\u0924\u093e \u092c\u0932\u091c\u093f\u0902\u0926\u0930 \u0938\u093f\u0902\u0939 \u0915\u0940 \u092a\u0902\u091c\u093e\u092c \u092e\u0947\u0902 \u0918\u0930 \u0915\u0947 ...   \n",
      "1  \u0915\u0947\u0902\u0926\u094d\u0930\u0940\u092f \u092e\u0902\u0924\u094d\u0930\u0940 \u092c\u094b\u0932\u0947- \u092e\u0939\u093f\u0932\u093e \u0906\u0930\u0915\u094d\u0937\u0923 \u0932\u093e\u0928\u0947 \u0915\u093e \u0938\u093e\u0939...   \n",
      "2  \u0913\u092a\u0940\u090f\u0938 \u0932\u093e\u0917\u0942 \u0915\u0930\u0928\u0947 \u0938\u0947 \u0905\u0938\u094d\u0925\u093f\u0930 \u0939\u094b \u0938\u0915\u0924\u0940 \u0939\u0948 \u0930\u093e\u091c\u094d\u092f\u094b\u0902 \u0915...   \n",
      "3  \u0924\u092e\u093f\u0932\u0928\u093e\u0921\u0941 \u092e\u0947\u0902 \u0936\u093e\u0935\u0930\u092e\u093e \u0916\u093e\u0928\u0947 \u0938\u0947 14 \u0935\u0930\u094d\u0937\u0940\u092f \u091b\u093e\u0924\u094d\u0930\u093e \u0915...   \n",
      "4  \u092e\u0923\u093f\u092a\u0941\u0930 \u092e\u0947\u0902 \u092e\u0941\u0916\u094d\u092f\u092e\u0902\u0924\u094d\u0930\u0940 \u0915\u0947 \u0906\u0936\u094d\u0935\u093e\u0938\u0928 \u0915\u0947 \u092c\u093e\u0926 \u092e\u093e\u0930\u0947 ...   \n",
      "\n",
      "                                             Content  \\\n",
      "0  \u0915\u093e\u0902\u0917\u094d\u0930\u0947\u0938 \u0928\u0947\u0924\u093e \u092c\u0932\u091c\u093f\u0902\u0926\u0930 \u0938\u093f\u0902\u0939 \u0915\u0940 \u0938\u094b\u092e\u0935\u093e\u0930 \u0915\u094b \u092a\u0902\u091c\u093e\u092c ...   \n",
      "1  \u0915\u0947\u0902\u0926\u094d\u0930\u0940\u092f \u092e\u0902\u0924\u094d\u0930\u0940 \u092a\u094d\u0930\u0939\u094d\u0932\u093e\u0926 \u092a\u091f\u0947\u0932 \u0928\u0947 \u0932\u094b\u0915\u0938\u092d\u093e \u0914\u0930 \u0935\u093f\u0927...   \n",
      "2  \u0906\u0930\u092c\u0940\u0906\u0908 \u0915\u0947 5 \u0905\u0927\u093f\u0915\u093e\u0930\u093f\u092f\u094b\u0902 \u0928\u0947 \u090f\u0915 \u0932\u0947\u0916 \u092e\u0947\u0902 \u0932\u093f\u0916\u093e \u0939\u0948 \u0915...   \n",
      "3  \u0928\u093e\u092e\u0915\u094d\u0915\u0932 (\u0924\u092e\u093f\u0932\u0928\u093e\u0921\u0941) \u092e\u0947\u0902 \u0936\u093e\u0935\u0930\u092e\u093e \u0916\u093e\u0928\u0947 \u0938\u0947 \u0938\u094b\u092e\u0935\u093e\u0930 \u0915...   \n",
      "4  \u092e\u0923\u093f\u092a\u0941\u0930 \u0915\u0947 \u092e\u0941\u0916\u094d\u092f\u092e\u0902\u0924\u094d\u0930\u0940 \u090f\u0928 \u092c\u0940\u0930\u0947\u0928 \u0938\u093f\u0902\u0939 \u0915\u0947 \u0906\u0936\u094d\u0935\u093e\u0938\u0928...   \n",
      "\n",
      "            News Categories        Date  \n",
      "0              ['national']  19-09-2023  \n",
      "1  ['politics', 'national']  19-09-2023  \n",
      "2  ['business', 'national']  19-09-2023  \n",
      "3              ['national']  19-09-2023  \n",
      "4              ['national']  19-09-2023  \n",
      "\n",
      "Columns: ['Headline', 'Content', 'News Categories', 'Date']\n",
      "Dataset Size: 129934\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('/content/hindi_news_dataset.csv', encoding='utf-8',nrows=129934) #add if in dataset error ,nrows=129934\n",
    "    print(\"Dataset (first 5 rows):\")\n",
    "    print(df.head())\n",
    "    print(\"\\nColumns:\", df.columns.tolist())\n",
    "    print(\"Dataset Size:\", len(df))\n",
    "except Exception as e:\n",
    "    print(\"Error loading CSV:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRFyDbuyMKoO"
   },
   "source": [
    "**Hugging Face Authentication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOBE3h9FwPz3"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Replace with your Hugging Face token\n",
    "hf_token = \"hf_ipSKdsanmmMCHwHHGYYVCZoyZWxzy*****\"  # Paste your token here\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4tUWKMYxo1a",
    "outputId": "5639cb8d-6b17-47f6-af68-fdefc290e1f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful!\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from google.colab import userdata\n",
    "\n",
    "# Authenticate with Hugging Face\n",
    "try:\n",
    "    login(token=userdata.get('HF_TOKEN'))\n",
    "    print(\"Authentication successful!\")\n",
    "except Exception as e:\n",
    "    print(\"Authentication failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wWMkXLSwiae"
   },
   "source": [
    "# **Preprocessing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315,
     "referenced_widgets": [
      "322f577591354f57839d4adb31133f24",
      "90a1f5c4903b4a8fbe196f91a76e375e",
      "66c88fa027984f5ba176c222a3019bb2",
      "6248dd87fccf4c46958a9a06276671a5",
      "6e0168633ede4c9a98e38743e434cc71",
      "f4f41620796a49fa93061c66451f9050",
      "9a216d65c2b34340bbdccbaaa4aae903",
      "2ac5f167a75c439ca28bc37a705b5942",
      "0a96beed9324426886d1ea412564bbdf",
      "ec64de527c1f498585282ab67f922932",
      "0b278ac2e01f4dcab8875e197e213db9",
      "9fd5d8092ee6482ab536d667f8eeef6b",
      "f18a28dafd9044eb9d3fe79ce2102fc5",
      "9c880851a33846028c254a65c1b33b68",
      "3a49858da3654e3db69866b2fab0a256",
      "4c76576808894271b057f9334323f695",
      "527073229a1c4c5cbea962a8b8adf9f2",
      "2db9c01af27a49d0863aa223a6616974",
      "83e79716251342a38f457c43c31cec97",
      "070e04a4d6864bb293abdbf0c65db8ca",
      "c1ed4e70610841b6b646ebffaa46759f",
      "12fcc9ba74f74eee9ddab15a5f2ed01c",
      "62b3f94e401b4f43aa2a673b13f227cc",
      "4e718a480c4e4f2ab1ca2e08fc69835b",
      "e43da19660fb4fcdb4acc7ccaf7a3265",
      "7bc19f6a20ab4e10a96cfc637ce45bc8",
      "d814bdcdcc0f4d3e815d6f877688983a",
      "7786c9994e4e4174b5e71f7af90b208d",
      "8bdcd03a618740f1ac759e98a95976d2",
      "0b767a8520eb4ace96f08dc96a21ffcf",
      "102bbe47a945400abfd169a06008cfb1",
      "e7aa4ee6b3384aef841f80ef84dc7ca1",
      "209c1316e61943f596850e6b2aaee528",
      "891f7392dade4cfca10c932c21107f7c",
      "e34ac3852dae43ea8c9cf5d5ab857cfd",
      "373904f953c8413cb21d104ca8c38582",
      "779a4d30b9ef436585cd2bdf8c228b11",
      "eb9ae6514e1b49559115f21dc8671148",
      "750c97ac6e50463984c966d01e5eed2c",
      "40b0b52e6f6e4e15a35a6640ebdc7871",
      "b7f78cc1aa9d402499b32a0d9fab3932",
      "7cd1c7a05dc748eea1ff24a9f0a41265",
      "dbbc267fddc04e189dc3117b2b5cb4f2",
      "76ed915556414ed8a7bc17d417503390",
      "e27b3e2de17f416d956e67b882fcafbb",
      "20690ff08c844ef6982eaafe6859219b",
      "960a012486854a7dbb597f965cfbcfb3",
      "d1e0d53e0eb746d28f1d05b468a185df",
      "7fdf1efaeb5540b29790e52a946ac40f",
      "bcea913112ad4623a5a153ffc77cd06b",
      "de1aa63b0a73434d9603b5bff4cf5ade",
      "5a23d0cecdf84d959fa3dd19d9a0baa8",
      "5ec777e1c01e4b67897587d96f6e26db",
      "15c457b601084e55997ba297ec6f12d4",
      "81326f88bdfb40768d40605d67b92762",
      "4130113b6452460c9251c546eab1dfe8",
      "0ddede7992b54c69b3a01c23716d410d",
      "7db2768bf4b74601a5621d8ee09006ae",
      "548586c4c0aa4edaaf1b75643411e0f2",
      "c785d504756c48039e8f3ee097cb53f0",
      "8e93346e40f84fb7aee504273c11283b",
      "75e39515c3744858bac64fb81bf6ad04",
      "fcae726efccf48e08a03672c92016663",
      "c007e91b8cd543268cfcabd518d24a5e",
      "eb66b99988cf45289d57b12fb842583d",
      "f3d90310a55e4a51ba4bf0070af9cbd9",
      "199dafc3dd424d2e8347badfdf438427",
      "5f61fae6c00c4a2fbad765617767e442",
      "02650932dc0a4b29abdc021a58e8abef",
      "07c1d6c0cc8249afbf9d8d18f4e33b3b",
      "ad77bd68971f43ceb7bed63fc76a7882",
      "b4480cd4cdce431eb58c0827d4060081",
      "13874862b9be411ca2608cec1e58428f",
      "26aa7e3cc3344304bba3e0a5d51c1322",
      "5bbd198a19f34a13abe85dfc28b547f3",
      "34de853b33cd4534b2046389e7655870",
      "8501fa0a88a5443cae22c9163a343bcb"
     ]
    },
    "id": "JshNppNIwkxw",
    "outputId": "24abc8f2-c391-4174-d0c8-33df3caefbda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Dataset Size: 129934\n",
      "Sample Article: \u0915\u093e\u0902\u0917\u094d\u0930\u0947\u0938 \u0928\u0947\u0924\u093e \u092c\u0932\u091c\u093f\u0902\u0926\u0930 \u0938\u093f\u0902\u0939 \u0915\u0940 \u0938\u094b\u092e\u0935\u093e\u0930 \u0915\u094b \u092a\u0902\u091c\u093e\u092c \u0915\u0947 \u092e\u094b\u0917\u093e \u092e\u0947\u0902 \u0909\u0928\u0915\u0947 \u0918\u0930 \u092e\u0947\u0902 \u0917\u094b\u0932\u0940 \u092e\u093e\u0930\u0915\u0930 \u0939\u0924\u094d\u092f\u093e \u0915\u0930 \u0926\u0940 \u0917\u0908\u0964 \u0911\u0928\u0932\u093e\u0907\u0928 \u0938\u093e\u092e\u0928\u0947 \u0906\u090f \u0938\u0940\u0938\u0940\u091f\u0940\u0935\u0940 \u092b\u0941\u091f\u0947\u091c \u092e\u0947\u0902 \u092c\u0932\u091c\u093f\u0902\u0926\u0930 \u0915\u094b \u0917\u094b\u0932\u093f\u092f\u093e\u0902 \u092e\u093e\u0930\u0924\u093e \u0939\u0941\u0906 \u090f\u0915 \u0939\u092e\u0932\u093e\u0935\u0930 \u0926\u093f\u0916 \u0930\u0939\u093e \u0939\u0948\u0964 \u092a\u0941\u0932\u093f\u0938 \u0928\u0947 \u092c\u0924\u093e\u092f\u093e, \"\u092c\u0932\u091c\u093f\u0902\u0926\u0930 \u0915\u094b \u090f\u0915 \u0917\u094b\u0932\u0940 \u0938\u0940\u0928\u0947 \u092e\u0947\u0902 \u0932\u0917\u0940 \u0914\u0930 \u0906\u0936\u0902\u0915\u093e \u0939\u0948 \u0915\u093f \u0926\u0942\u0938\u0930\u093e \u0939\u092e\u0932\u093e\u0935\u0930 \u0918\u0930 \u0915\u0947 \u092c\u093e\u0939\u0930 \u092c\u093e\u0907\u0915 \u092a\u0930 \u0938\u0935\u093e\u0930 \u0925\u093e\u0964\"\n",
      "Sample Summary: \u0915\u093e\u0902\u0917\u094d\u0930\u0947\u0938 \u0928\u0947\u0924\u093e \u092c\u0932\u091c\u093f\u0902\u0926\u0930 \u0938\u093f\u0902\u0939 \u0915\u0940 \u092a\u0902\u091c\u093e\u092c \u092e\u0947\u0902 \u0918\u0930 \u0915\u0947 \u0905\u0902\u0926\u0930 \u0917\u094b\u0932\u0940 \u092e\u093e\u0930\u0915\u0930 \u0915\u0940 \u0917\u0908 \u0939\u0924\u094d\u092f\u093e\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322f577591354f57839d4adb31133f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/485 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd5d8092ee6482ab536d667f8eeef6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/832 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b3f94e401b4f43aa2a673b13f227cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891f7392dade4cfca10c932c21107f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27b3e2de17f416d956e67b882fcafbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/398 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4130113b6452460c9251c546eab1dfe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199dafc3dd424d2e8347badfdf438427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('/content/hindi_news_dataset.csv', encoding='utf-8',nrows=129934) #add if in dataset error ,nrows=129934\n",
    "\n",
    "# Rename columns\n",
    "df = df.rename(columns={'Content': 'article', 'Headline': 'summary'})\n",
    "\n",
    "# Clean text function\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.strip().replace('\\n', ' ').replace('\\r', '').replace('  ', ' ')\n",
    "        return text\n",
    "    return \"\"\n",
    "\n",
    "# Apply cleaning\n",
    "df['article'] = df['article'].apply(clean_text)\n",
    "df['summary'] = df['summary'].apply(clean_text)\n",
    "\n",
    "# Remove empty rows\n",
    "df = df[df['article'].str.len() > 0]\n",
    "df = df[df['summary'].str.len() > 0]\n",
    "\n",
    "# Verify cleaned data\n",
    "print(\"Cleaned Dataset Size:\", len(df))\n",
    "print(\"Sample Article:\", df['article'].iloc[0])\n",
    "print(\"Sample Summary:\", df['summary'].iloc[0])\n",
    "\n",
    "# Use a subset to manage memory\n",
    "df = df.sample(5000, random_state=42)\n",
    "\n",
    "# Split into train and test (80% train, 20% test)\n",
    "train_size = int(0.8 * len(df))\n",
    "train_df = df[:train_size]\n",
    "test_df = df[train_size:]\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df[['article', 'summary']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['article', 'summary']])\n",
    "dataset = DatasetDict({'train': train_dataset, 'test': test_dataset})\n",
    "\n",
    "# Load tokenizer\n",
    "model_name = \"ai4bharat/IndicBARTSS\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set the source and target language for mBART\n",
    "tokenizer.src_lang = \"hi_IN\"  # Hindi\n",
    "tokenizer.tgt_lang = \"hi_IN\"  # Hindi\n",
    "\n",
    "# Tokenize dataset\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples['article']\n",
    "    targets = examples['summary']\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(targets, max_length=150, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIH3DWB00vYb"
   },
   "source": [
    "# **Fine-Tune and train IndicBARTSS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626,
     "referenced_widgets": [
      "7ad84b317f33459e818212f372ece275",
      "8404abdf15ed4124a45c443236de67b5",
      "c360c450a5a44864a463657998779d7d",
      "b1a2bf039948403da84c80b13d332a22",
      "6a9dcb5e0d86459d95156508246edbb9",
      "e1a223e5c4044cc0b6b25ada4ade6dea",
      "464b88dad4aa4e9a90c20f70076e6638",
      "3deafa2f8c734904afe694a6f901de7a",
      "e5aaa711d45c4b5bae5baf367eb5e5d0",
      "fe4914f146a1456198b4f737d64e7a5c",
      "c9cc7dbbe4a54c1b9ec8dd8f14ffc9a0",
      "a0c88f4b81144a1e844035ce6a00a824",
      "d8f16a93d28b4520a37290a37f50144e",
      "ae6fe37f115842dcb64e8cd4ec96402d",
      "a89fb34af3d94afc868b918c648221e3",
      "6dfeb9fb2e394da6abbcb6eb2dc0fbe2",
      "3cb6450798354401956e6384fc928c4e",
      "a8ada9b7eddf42a5b5ea10253ec882ce",
      "ecb5f50572274ed5981027b416fbdfe2",
      "bc3fee31e3f64e5f82fe758af8aa37f9",
      "3b6cd6b8dd8a43469528a4dd515caa54",
      "850e53615dd1492c995cd4e0ea63b223"
     ]
    },
    "id": "x7uQn7_90wZp",
    "outputId": "889e0060-64f5-4376-d7e3-d6c4474001f2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad84b317f33459e818212f372ece275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/976M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c88f4b81144a1e844035ce6a00a824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/976M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpavova8202\u001b[0m (\u001b[33mpavova8202-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250605_022541-h2m44ejm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pavova8202-/huggingface/runs/h2m44ejm' target=\"_blank\">/content/drive/My Drive/indicbartss_finetuned</a></strong> to <a href='https://wandb.ai/pavova8202-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pavova8202-/huggingface' target=\"_blank\">https://wandb.ai/pavova8202-/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pavova8202-/huggingface/runs/h2m44ejm' target=\"_blank\">https://wandb.ai/pavova8202-/huggingface/runs/h2m44ejm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 33:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.302900</td>\n",
       "      <td>4.266286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.819500</td>\n",
       "      <td>1.063501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.041400</td>\n",
       "      <td>0.637006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/content/drive/My Drive/indicbartss_finetuned/tokenizer_config.json',\n",
       " '/content/drive/My Drive/indicbartss_finetuned/special_tokens_map.json',\n",
       " '/content/drive/My Drive/indicbartss_finetuned/spiece.model',\n",
       " '/content/drive/My Drive/indicbartss_finetuned/added_tokens.json',\n",
       " '/content/drive/My Drive/indicbartss_finetuned/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
    "from google.colab import userdata\n",
    "\n",
    "# Load model\n",
    "model_name = \"ai4bharat/IndicBARTSS\"\n",
    "hf_token = userdata.get('HF_TOKEN')  # Get token from Colab Secrets\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, token=hf_token if hf_token else None)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/My Drive/indicbartss_finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    gradient_accumulation_steps=2,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save model to Google Drive\n",
    "model.save_pretrained(\"/content/drive/My Drive/indicbartss_finetuned\")\n",
    "tokenizer.save_pretrained(\"/content/drive/My Drive/indicbartss_finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTR4Lle8-D-N"
   },
   "source": [
    "# **Test the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgl6lied-E8s",
    "outputId": "2b58b80d-af74-4f7b-83ca-cd403f41ecad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1:\n",
      "Article: \u092a\u093e\u0915\u093f\u0938\u094d\u0924\u093e\u0928 \u0915\u0947 \u092a\u0942\u0930\u094d\u0935 \u092a\u094d\u0930\u0927\u093e\u0928\u092e\u0902\u0924\u094d\u0930\u0940 \u0907\u092e\u0930\u093e\u0928 \u0916\u093e\u0928 \u0915\u0940 \u092a\u093e\u0930\u094d\u091f\u0940 '\u092a\u093e\u0915\u093f\u0938\u094d\u0924\u093e\u0928 \u0924\u0939\u0930\u0940\u0915-\u090f-\u0907\u0902\u0938\u093e\u092b' (\u092a\u0940\u091f\u0940\u0906\u0908) \u0928\u0947 \u092a\u093e\u0915 \u0938\u0947\u0928\u093e \u092a\u0930 \u0907\u092e\u0930\u093e\u0928 \u0915\u0947 \u092d\u0924\u0940\u091c\u0947 \u0939\u0938\u0928 \u0928\u093f\u092f\u093e\u091c\u093c\u0940 \u0915\u094b \u0906\u0930\u094d\u092e\u0940 \u0915\u0938\u094d\u091f\u0921\u0940 \u0938\u0947 \u0905\u0917\u0935\u093e \u0915\u0930\u0928\u0947 \u0915\u093e \u0906\u0930\u094b\u092a \u0932\u0917\u093e\u092f\u093e \u0939\u0948\u0964 \u092f\u0939 \u0906\u0930\u094b\u092a \u0924\u092c \u0938\u093e\u092e\u0928\u0947 \u0906\u092f\u093e \u0939\u0948 \u091c\u092c \u0907\u092e\u0930\u093e\u0928 \u0928\u0947 \u0938\u0947\u0928\u093e \u092a\u094d\u0930\u092e\u0941\u0916 \u0905\u0938\u0940\u092e \u092e\u0941\u0928\u0940\u0930 \u0915\u094b \u0909\u0928\u0915\u0940 \u092a\u0924\u094d\u0928\u0940 \u092c\u0941\u0936\u0930\u093e \u092c\u0940\u092c\u0940 \u0915\u094b \u091c\u0947\u0932 \u092e\u0947\u0902 \u0930\u0916\u0928\u0947 \u0915\u0947 \u0932\u093f\u090f \u0938\u0940\u0927\u0947 \u0924\u094c\u0930 \u092a\u0930 \u095b\u093f\u092e\u094d\u092e\u0947\u0926\u093e\u0930 \u0920\u0939\u0930\u093e\u092f\u093e \u0925\u093e\u0964\n",
      "Reference Summary: \u092a\u093e\u0915\u093f\u0938\u094d\u0924\u093e\u0928 \u0915\u0947 \u092a\u0942\u0930\u094d\u0935 \u092a\u0940\u090f\u092e \u0907\u092e\u0930\u093e\u0928 \u0915\u0940 \u092a\u093e\u0930\u094d\u091f\u0940 \u0928\u0947 \u0938\u0947\u0928\u093e \u092a\u0930 \u0932\u0917\u093e\u092f\u093e \u0909\u0928\u0915\u0947 \u092d\u0924\u0940\u091c\u0947 \u0915\u093e \u0905\u092a\u0939\u0930\u0923 \u0915\u0930\u0928\u0947 \u0915\u093e \u0906\u0930\u094b\u092a\n",
      "Generated Summary: \u092a\u093e\u0915\u093f\u0938\u094d\u0924\u093e\u0928 \u0915\u0947 \u092a\u0942\u0930\u094d\u0935 \u092a\u094d\u0930\u0927\u093e\u0928\u092e\u0902\u0924\u094d\u0930\u0940 \u0907\u092e\u0930\u093e\u0928 \u0916\u093e\u0928 \u0915\u0940 \u092a\u093e\u0930\u094d\u091f\u0940 '\u092a\u093e\u0915\u093f\u0938\u094d\u0924\u093e\u0928 \u0924\u0939\u0930\u0940\u0915-\u090f-\u0907\u0902\u0938\u093e\u092b' \u0928\u0947 \u092a\u093e\u0915 \u0938\u0947\u0928\u093e \u092a\u0930 \u0907\u092e\u0930\u093e\u0928 \u0915\u0947 \u092d\u0924\u0940\u091c\u0947 \u0915\u0940 \u092a\u0924\u094d\u0928\u0940 \u092c\u0941\u0936\u0930\u093e \u092c\u0940\u092c\u0940 \u0915\u094b \u0906\u0930\u094d\u092e\u0940 \u0915\u0938\u094d\u091f\u0921\u0940 \u0938\u0947 \u0905\u0917\u0935\u093e \u0915\u0930\u0928\u0947 \u0915\u093e \u0906\u0930\u094b\u092a \u0932\u0917\u093e\u092f\u093e \u0939\u0948: \u0907\u092e\u0930\u093e\u0928 \u0928\u0947 \u092a\u093e\u0915 \u0938\u0947\u0928\u093e \u092a\u0930 \u0907\u092e\u0930\u093e\u0928 \u0915\u0947 \u092d\u0924\u0940\u091c\u0947 \u0939\u0938\u0928 \u0928\u093f\u092f\u093e\u091c\u093c\u0940 \u0915\u094b \u0906\u0930\u094d\u092e\u0940 \u0915\u0938\u094d\u091f\u0921\u0940 \u0938\u0947 \u0905\u0917\u0935\u093e \u0915\u0930\u0928\u0947 \u0915\u093e \u0906\u0930\u094b\u092a \u0932\u0917\u093e\u092f\u093e: \u0907\u092e\u0930\u093e\u0928 \u0928\u0947 \u091c\u0924\u093e\u092f\u093e \u0924\n",
      "\n",
      "Sample 2:\n",
      "Article: \u092d\u093e\u0930\u0924 \u0928\u0947 \u092e\u0902\u0917\u0932\u0935\u093e\u0930 \u0915\u094b \u0915\u0928\u093e\u0921\u093e \u0915\u0947 \u0936\u0940\u0930\u094d\u0937 \u0930\u093e\u091c\u0928\u092f\u093f\u0915 \u0915\u094b \u0928\u093f\u0937\u094d\u0915\u093e\u0938\u093f\u0924 \u0915\u0930 \u0926\u093f\u092f\u093e\u0964 \u0915\u0928\u093e\u0921\u093e\u0908 \u092a\u094d\u0930\u0927\u093e\u0928\u092e\u0902\u0924\u094d\u0930\u0940 \u091c\u0938\u094d\u091f\u093f\u0928 \u091f\u094d\u0930\u0942\u0921\u094b \u0928\u0947 \u0915\u0939\u093e \u0925\u093e \u0915\u093f \u0916\u093e\u0932\u093f\u0938\u094d\u0924\u093e\u0928\u0940 \u0906\u0924\u0902\u0915\u0940 \u0939\u0930\u0926\u0940\u092a \u0938\u093f\u0902\u0939 \u0928\u093f\u091c\u094d\u091c\u0930 \u0915\u0940 \u0939\u0924\u094d\u092f\u093e \u092e\u0947\u0902 \u092d\u093e\u0930\u0924 \u0938\u0930\u0915\u093e\u0930 \u0915\u0947 \u090f\u091c\u0947\u0902\u091f\u094b\u0902 \u0915\u093e \u0939\u093e\u0925 \u0939\u094b \u0938\u0915\u0924\u093e \u0939\u0948 \u091c\u093f\u0938\u0915\u0947 \u092c\u093e\u0926 \u0915\u0928\u093e\u0921\u093e \u0928\u0947 \u0936\u0940\u0930\u094d\u0937 \u092d\u093e\u0930\u0924\u0940\u092f \u0930\u093e\u091c\u0928\u092f\u093f\u0915 \u0915\u094b \u0928\u093f\u0937\u094d\u0915\u093e\u0938\u093f\u0924 \u0915\u093f\u092f\u093e \u0925\u093e\u0964 \u092d\u093e\u0930\u0924 \u0928\u0947 \u0915\u0928\u093e\u0921\u093e\u0908 \u0930\u093e\u091c\u0928\u092f\u093f\u0915 \u0915\u094b 5-\u0926\u093f\u0928\u094b\u0902 \u092e\u0947\u0902 \u092d\u093e\u0930\u0924 \u091b\u094b\u0921\u093c\u0928\u0947 \u0915\u094b \u0915\u0939\u093e \u0939\u0948\u0964\n",
      "Reference Summary: \u092d\u093e\u0930\u0924 \u0928\u0947 '\u091c\u0948\u0938\u0947 \u0915\u094b \u0924\u0948\u0938\u093e' \u0915\u093e\u0930\u094d\u0930\u0935\u093e\u0908 \u0915\u0930\u0924\u0947 \u0939\u0941\u090f \u0936\u0940\u0930\u094d\u0937 \u0915\u0928\u093e\u0921\u093e\u0908 \u0930\u093e\u091c\u0928\u092f\u093f\u0915 \u0915\u094b \u0915\u093f\u092f\u093e \u0928\u093f\u0937\u094d\u0915\u093e\u0938\u093f\u0924\n",
      "Generated Summary: \u0915\u0928\u093e\u0921\u093e \u0915\u0947 \u0936\u0940\u0930\u094d\u0937 \u0930\u093e\u091c\u0928\u092f\u093f\u0915 \u0915\u094b \u0928\u093f\u0937\u094d\u0915\u093e\u0938\u093f\u0924 \u0915\u0930 \u0926\u093f\u092f\u093e \u0917\u092f\u093e \u092d\u093e\u0930\u0924: \u0915\u0928\u093e\u0921\u093e\u0908 \u0930\u093e\u091c\u0928\u092f\u093f\u0915 \u0915\u094b \u0928\u093f\u0937\u094d\u0915\u093e\u0938\u093f\u0924, \u0915\u0928\u093e\u0921\u093e\u0908 \u0930\u093e\u091c\u0928\u092f\u093f\u0915 \u0915\u094b \u0928\u093f\u0937\u094d\u0915\u093e\u0938\u093f\u0924, \u0915\u0928\u093e\u0921\u093e\u0908 \u0930\u093e\u091c\u0928\u092f\u093f\u0915 \u0915\u094b \u0928\u093f\u0937\u094d\u0915\u093e\u0938\u093f\u0924 \u0915\u0930 \u0926\u093f\u092f\u093e \u0915\u0928\u093e\u0921\u093e: \u0915\u0928\u093e\u0921\u093e\u0908 \u0930\u093e\u091c\u0928\u092f\u093f\u0915 \u0915\u094b 5-\u0926\u093f\u0928\u094b\u0902 \u092e\u0947\u0902 \u092d\u093e\u0930\u0924 \u091b\u094b\u0921\u093c\u0928\u0947 \u0915\u094b \u0915\u0939\u093e \u0925\u093e \u0915\u0928\u093e\u0921\u093e: \u0915\u0928\u093e\u0921\u093e\u0908 \u0930\u093e\u091c\u0928\u092f\u093f\u0915 \u0915\u094b \u0928\u093f\u0937\u094d\u0915\u093e\u0938\u093f\u0924, \u0915\u0928\u093e\u0921\u093e\u0908 \u0930\u093e\u091c\u0928\u092f\u093f\u0915 \u0915\u094b 5-\u0926\u093f\u0928\u094b\u0902 \u092e\u0947\u0902 \u092d\u093e\u0930\u0924 \u091b\u094b\u0921\u093c\u0928\u0947 \u0915\u094b \u0915\u0939\u093e \u0925\u093e \u0915\u0928\u093e\u0921\u093e\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load fine-tuned model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/My Drive/indicbartss_finetuned\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/My Drive/indicbartss_finetuned\")\n",
    "\n",
    "# Define summarization function\n",
    "def summarize_text(article):\n",
    "    inputs = tokenizer(\n",
    "        article,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=150,\n",
    "        min_length=50,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Test on samples\n",
    "for i in range(2):\n",
    "    article = test_df['article'].iloc[i]\n",
    "    reference = test_df['summary'].iloc[i]\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(\"Article:\", article)\n",
    "    print(\"Reference Summary:\", reference)\n",
    "    print(\"Generated Summary:\", summarize_text(article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z69x3BcX_EPt"
   },
   "source": [
    "# **Creating gradio Interface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQ1HFjYZ_H2L"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/My Drive/indicbartss_finetuned\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/My Drive/indicbartss_finetuned\")\n",
    "\n",
    "# Define summarization function\n",
    "def summarize_text(article):\n",
    "    inputs = tokenizer(\n",
    "        article,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=1024,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=150,\n",
    "        min_length=50,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Create Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=summarize_text,\n",
    "    inputs=gr.Textbox(lines=10, placeholder=\"Paste news article here...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Indian News Summarization\",\n",
    "    description=\"Enter a news article to get a concise summary.\"\n",
    ")\n",
    "\n",
    "# Launch interface\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
